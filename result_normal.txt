(ml) cheng@cheng-Alienware-17-R4:~/Desktop/sta561$ python init.py 
Using TensorFlow backend.
WARNING:tensorflow:From /home/cheng/anaconda3/envs/ml/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/cheng/anaconda3/envs/ml/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Found 14221 images belonging to 10 classes.
Found 8196 images belonging to 10 classes.
WARNING:tensorflow:From /home/cheng/anaconda3/envs/ml/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/25
2019-04-16 19:26:43.792928: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-04-16 19:26:43.798511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-04-16 19:26:43.798738: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d352ff26a0 executing computations on platform Host. Devices:
2019-04-16 19:26:43.798793: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-16 19:26:43.871477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-16 19:26:43.872105: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d351bebef0 executing computations on platform CUDA. Devices:
2019-04-16 19:26:43.872141: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2019-04-16 19:26:43.872507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.771
pciBusID: 0000:01:00.0
totalMemory: 7.91GiB freeMemory: 7.49GiB
2019-04-16 19:26:43.872559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-04-16 19:26:43.873376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 19:26:43.873408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-04-16 19:26:43.873417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-04-16 19:26:43.873756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7290 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-04-16 19:26:46.552994: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
444/444 [==============================] - 196s 442ms/step - loss: 2.0651 - acc: 0.2287 - val_loss: 1.1633 - val_acc: 0.6238
Epoch 2/25
444/444 [==============================] - 194s 437ms/step - loss: 0.8588 - acc: 0.7214 - val_loss: 0.3377 - val_acc: 0.9031
Epoch 3/25
444/444 [==============================] - 202s 455ms/step - loss: 0.4291 - acc: 0.8648 - val_loss: 0.2266 - val_acc: 0.9381
Epoch 4/25
444/444 [==============================] - 199s 449ms/step - loss: 0.3026 - acc: 0.9053 - val_loss: 0.1473 - val_acc: 0.9559
Epoch 5/25
444/444 [==============================] - 195s 438ms/step - loss: 0.2336 - acc: 0.9273 - val_loss: 0.1187 - val_acc: 0.9690
Epoch 6/25
444/444 [==============================] - 194s 438ms/step - loss: 0.1907 - acc: 0.9426 - val_loss: 0.1188 - val_acc: 0.9705
Epoch 7/25
444/444 [==============================] - 192s 433ms/step - loss: 0.1626 - acc: 0.9510 - val_loss: 0.0898 - val_acc: 0.9727
Epoch 8/25
444/444 [==============================] - 197s 443ms/step - loss: 0.1412 - acc: 0.9555 - val_loss: 0.0806 - val_acc: 0.9768
Epoch 9/25
444/444 [==============================] - 195s 440ms/step - loss: 0.1235 - acc: 0.9626 - val_loss: 0.0763 - val_acc: 0.9792
Epoch 10/25
444/444 [==============================] - 199s 448ms/step - loss: 0.1134 - acc: 0.9651 - val_loss: 0.0814 - val_acc: 0.9803
Epoch 11/25
444/444 [==============================] - 196s 441ms/step - loss: 0.1087 - acc: 0.9673 - val_loss: 0.0753 - val_acc: 0.9820
Epoch 12/25
444/444 [==============================] - 198s 445ms/step - loss: 0.0915 - acc: 0.9721 - val_loss: 0.0816 - val_acc: 0.9810
Epoch 13/25
444/444 [==============================] - 194s 438ms/step - loss: 0.0914 - acc: 0.9725 - val_loss: 0.0576 - val_acc: 0.9851
Epoch 14/25
444/444 [==============================] - 193s 435ms/step - loss: 0.0801 - acc: 0.9766 - val_loss: 0.0690 - val_acc: 0.9846
Epoch 15/25
444/444 [==============================] - 193s 435ms/step - loss: 0.0689 - acc: 0.9780 - val_loss: 0.0550 - val_acc: 0.9855
Epoch 16/25
444/444 [==============================] - 192s 433ms/step - loss: 0.0751 - acc: 0.9773 - val_loss: 0.0512 - val_acc: 0.9847
Epoch 17/25
444/444 [==============================] - 195s 438ms/step - loss: 0.0595 - acc: 0.9812 - val_loss: 0.0818 - val_acc: 0.9809
Epoch 18/25
444/444 [==============================] - 190s 429ms/step - loss: 0.0569 - acc: 0.9834 - val_loss: 0.0476 - val_acc: 0.9871
Epoch 19/25
444/444 [==============================] - 191s 431ms/step - loss: 0.0579 - acc: 0.9823 - val_loss: 0.0552 - val_acc: 0.9858
Epoch 20/25
444/444 [==============================] - 190s 429ms/step - loss: 0.0509 - acc: 0.9836 - val_loss: 0.0512 - val_acc: 0.9878
Epoch 21/25
444/444 [==============================] - 194s 438ms/step - loss: 0.0522 - acc: 0.9828 - val_loss: 0.0405 - val_acc: 0.9873
Epoch 22/25
444/444 [==============================] - 204s 459ms/step - loss: 0.0501 - acc: 0.9847 - val_loss: 0.0369 - val_acc: 0.9886
Epoch 23/25
444/444 [==============================] - 204s 459ms/step - loss: 0.0470 - acc: 0.9849 - val_loss: 0.0458 - val_acc: 0.9875
Epoch 24/25
444/444 [==============================] - 202s 456ms/step - loss: 0.0425 - acc: 0.9860 - val_loss: 0.0436 - val_acc: 0.9881
Epoch 25/25
444/444 [==============================] - 202s 456ms/step - loss: 0.0435 - acc: 0.9863 - val_loss: 0.0594 - val_acc: 0.9860
initialization method 1
Traceback (most recent call last):
  File "init.py", line 108, in <module>
    print("total training time: {}".format(np.sum(times)))
TypeError: 'History' object has no attribute '__getitem__'

